---
title: "Assignment 3"
author: "Name 1, Name 2, Name 3"
date: "2019-10-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Instructions

Fill in your computations and answers to the assignment questions in this
RMarkdown document. When you are finished, click the "Knit" button on RStudio
to render an HTML document. You can then use your browser or tool of choice
to convert the HTML document to a PDF file.

This assignment is to be handed in through canvas on Monday Oct 7 at 11:00pm.
(Note that this due date is different from the due date given on the canvas
Admin page.) This is a group assignment.
You must join a group on canvas even if you want to work alone. Please upload one PDF file
with your solutions per group. 

15. This problem involves the Boston data set, which we saw in the lab
for this chapter. We will now try to predict per capita crime rate
using the other variables in this data set. In other words, per capita
crime rate is the response, and the other variables are the predictors.
(a) For each predictor, fit a simple linear regression model to predict
the response. Describe your results. In which of the models is
there a statistically significant association between the predictor
and the response? Create some plots to back up your assertions.
(b) Fit a multiple regression model to predict the response using
all of the predictors. Describe your results. For which predictors
can we reject the null hypothesis H0 : βj = 0?
(c) How do your results from (a) compare to your results from (b)?
Create a plot displaying the univariate regression coefficients
from (a) on the x-axis, and the multiple regression coefficients
from (b) on the y-axis. That is, each predictor is displayed as a
single point in the plot. Its coefficient in a simple linear regression
model is shown on the x-axis, and its coefficient estimate
in the multiple linear regression model is shown on the y-axis.
(d) Is there evidence of non-linear association between any of the
predictors and the response? To answer this question, for each
predictor X, fit a model of the form
Y = β0 + β1X + β2X2 + β3X3 + .

## Question 1 (Chapter 3, #15)

(a)

(b)

(c)

(d)

4. When the number of features p is large, there tends to be a deterioration
in the performance of KNN and other local approaches that
perform prediction using only observations that are near the test observation
for which a prediction must be made. This phenomenon is
known as the curse of dimensionality, and it ties into the fact that curse of dinon-parametric
approaches often perform poorly when p is large. We mensionality
will now investigate this curse.
(a) Suppose that we have a set of observations, each with measurements
on p = 1 feature, X. We assume that X is uniformly
(evenly) distributed on [0, 1]. Associated with each observation
is a response value. Suppose that we wish to predict a test observation’s
response using only observations that are within 10 % of
the range of X closest to that test observation. For instance, in
order to predict the response for a test observation with X = 0.6,
we will use observations in the range [0.55, 0.65]. On average,
what fraction of the available observations will we use to make
the prediction?
(b) Now suppose that we have a set of observations, each with
measurements on p = 2 features, X1 and X2. We assume that
(X1, X2) are uniformly distributed on [0, 1] × [0, 1]. We wish to
predict a test observation’s response using only observations that
are within 10 % of the range of X1 and within 10 % of the range
of X2 closest to that test observation. For instance, in order to
predict the response for a test observation with X1 = 0.6 and
X2 = 0.35, we will use observations in the range [0.55, 0.65] for
X1 and in the range [0.3, 0.4] for X2. On average, what fraction
of the available observations will we use to make the prediction?
(c) Now suppose that we have a set of observations on p = 100 features.
Again the observations are uniformly distributed on each
feature, and again each feature ranges in value from 0 to 1. We
wish to predict a test observation’s response using observations
within the 10 % of each feature’s range that is closest to that test
observation. What fraction of the available observations will we
use to make the prediction?
(d) Using your answers to parts (a)–(c), argue that a drawback of
KNN when p is large is that there are very few training observations
“near” any given test observation.
(e) Now suppose that we wish to make a prediction for a test observation
by creating a p-dimensional hypercube centered around
the test observation that contains, on average, 10 % of the training
observations. For p = 1, 2, and 100, what is the length of
each side of the hypercube? Comment on your answer.
Note: A hypercube is a generalization of a cube to an arbitrary
number of dimensions. When p = 1, a hypercube is simply a line
segment, when p = 2 it is a square, and when p = 100 it is a
100-dimensional cube


## Question 2 (Chapter 4, #4)

(a)

(b) 

(c)

(d) 

(e)

10. This question should be answered using the Weekly data set, which
is part of the ISLR package. This data is similar in nature to the
Smarket data from this chapter’s lab, except that it contains 1, 089
weekly returns for 21 years, from the beginning of 1990 to the end of
2010.
(a) Produce some numerical and graphical summaries of the Weekly
data. Do there appear to be any patterns?
(b) Use the full data set to perform a logistic regression with
Direction as the response and the five lag variables plus Volume
as predictors. Use the summary function to print the results. Do
any of the predictors appear to be statistically significant? If so,
which ones?
(c) Compute the confusion matrix and overall fraction of correct
predictions. Explain what the confusion matrix is telling you
about the types of mistakes made by logistic regression.
(d) Now fit the logistic regression model using a training data period
from 1990 to 2008, with Lag2 as the only predictor. Compute the
confusion matrix and the overall fraction of correct predictions
for the held out data (that is, the data from 2009 and 2010).
(e) Repeat (d) using LDA.
(f) Repeat (d) using QDA.
(g) Repeat (d) using KNN with K = 1.
(h) Which of these methods appears to provide the best results on
this data?

## Question 3 (Chapter 4, #10 parts (a)-(h), 9 marks)

```{r}
library(ISLR)
data(Weekly)
head(Weekly)
```


(a)

(b) 

(c)

(d) 

(e) 

(f) 

(g) 

(h)  